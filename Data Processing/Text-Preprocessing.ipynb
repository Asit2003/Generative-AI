{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65189e61-5f46-4c4d-a71d-5e781020522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f499dd8b-bef6-47fe-b71d-5407418a8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8705b036-fc85-4653-8887-c2c2633ecd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bfff37-9596-46cb-a23c-88e84a722022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7df5e8-ffcd-40fa-9903-2aae9850dd53",
   "metadata": {},
   "source": [
    "## Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c81802-d814-4380-b143-8919591bd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112e3de-f58e-40eb-86ee-3eb9dd162141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b3ea0ef-e87d-4db6-b4a4-eacf8b77f789",
   "metadata": {},
   "source": [
    "## Remove HTML tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc837e5-baf5-41a8-b4d2-a882c1458d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3547c505-0882-4f3f-90d5-b4bdf4afe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"<html> hii how are you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae45cad9-c36a-40b5-93df-11d101f25efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hii how are you'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5952620f-00dc-441f-a3b0-7a0392ea3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c2f2929-9c32-4b4d-9315-63210c000212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b032498-5109-44c9-b9b8-321c97a65dc5",
   "metadata": {},
   "source": [
    "## Remove URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d1afc7-e94f-436c-a4e9-580891b5849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "021172e6-276f-4b6f-b733-6caafb15a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt='Check out my youtube https://www.youtube.com/dswithbappy dswithbappy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0262acf0-d99e-4598-9e15-4f44eb54ec57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check out my youtube  dswithbappy'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc884a73-5339-4248-b271-96ee1599723e",
   "metadata": {},
   "source": [
    "## Punctuation handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dea144f-c140-4376-888e-5e7b4f135364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcc4433c-625f-49d1-9c5c-5bbd19077899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = string.punctuation\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11b85f35-de8d-4251-bb97-02a882f1a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06c2d264-baff-4309-9713-9f40b9975186",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 =\"'what!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b02bc3cb-08ee-4a40-90a4-c0feeb220e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4cf884c-dd10-4189-8d0b-7a4be867114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd function to remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f739eac-0fe2-43b4-a7f6-54f6c3540644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17d93acd-85f0-4e9b-8449-249e6f9f8e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc1(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382277a-ade4-4db5-8ec6-8accb83efabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edd155f4-a055-4b7a-82c6-c9a53a207ecf",
   "metadata": {},
   "source": [
    "## chat conversion handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "090aeb5c-8d5c-442e-9723-7aa205031615",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "    'AFAIK':'As Far As I Know',\n",
    "    'AFK':'Away From Keyboard',\n",
    "    'ASAP':'As Soon As Possible',\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"OMG\": \"Oh My God\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"LOL\": \"Laugh Out Loud\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"GTG\": \"Got To Go\",\n",
    "    \"TTYT\": \"Talk To You Tomorrow\",\n",
    "    \"IDK\": \"I Don't Know\",\n",
    "    \"TMI\": \"Too Much Information\",\n",
    "    \"IMHO\": \"In My Humble Opinion\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"TGIF\": \"Thank God It's Friday\",\n",
    "    \"FYA\": \"For Your Action\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8ef1dc8-d5e1-4424-b247-daa5eff09f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'As Far As I Know',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'FYI': 'For Your Information',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BTW': 'By The Way',\n",
       " 'OMG': 'Oh My God',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'LOL': 'Laugh Out Loud',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'GTG': 'Got To Go',\n",
       " 'TTYT': 'Talk To You Tomorrow',\n",
       " 'IDK': \"I Don't Know\",\n",
       " 'TMI': 'Too Much Information',\n",
       " 'IMHO': 'In My Humble Opinion',\n",
       " 'ICYMI': 'In Case You Missed It',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'TGIF': \"Thank God It's Friday\",\n",
       " 'FYA': 'For Your Action'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d30072be-c8d9-4f5c-9d19-0c3a18afa2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "731f7f85-9e9b-47ee-983b-8451ddff9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do your work As Soon As Possible'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(\"Do your work asap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9da3d-627f-47d1-aa7e-d6ff8a3767c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c439cf9-09cf-4fa4-8afa-e6666b4739ff",
   "metadata": {},
   "source": [
    "## incorrect text handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb50e45c-f6c2-4af0-88c4-90e71e08c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "927cdac2-215e-4bd6-875b-d48b9101e189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions during several generations are modified in the same manner.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = 'ceertain conditionas duriing seveal ggenerations aree moodified in the saame maner.'\n",
    "\n",
    "textBlb = TextBlob(incorrect_text)\n",
    "\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e54950-374d-441f-99d0-6d96afff7bf5",
   "metadata": {},
   "source": [
    "## stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ad3da27-c6df-43ac-bd26-917b90f7da2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dd3d966-ffc9-4130-acf4-1e953e2ad85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ab66efc-847b-441c-9c72-3f26ee0adb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ced42630-90c2-4a9e-863f-f328cc6d663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a048dcc-7271-428a-ae9c-e784b29764db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probably  all-time favorite movie,  story  selflessness, sacrifice  dedication   noble cause,    preachy  boring.   never gets old, despite   seen   15   times'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it\\'s not preachy or boring. it just never gets old, despite my having seen it some 15 or more times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7ebe9f1-bbea-406c-b6e6-b6edefac43c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6dbb8d5f-638b-4e77-aad0-5ef404f55ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c065c45a-c469-4847-8562-7ee02fc3172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     one    reviewers  mentioned   watching  1 oz e...\n",
       "1      wonderful little production.  filming techniq...\n",
       "2      thought    wonderful way  spend time    hot s...\n",
       "3     basically there's  family   little boy (jake) ...\n",
       "4     petter mattei's \"love   time  money\"   visuall...\n",
       "5     probably  all-time favorite movie,  story  sel...\n",
       "6      sure would like  see  resurrection    dated s...\n",
       "7      show   amazing, fresh & innovative idea   70'...\n",
       "8     encouraged   positive comments   film     look...\n",
       "9       like original gut wrenching laughter   like ...\n",
       "10    phil  alien  one   quirky films   humour  base...\n",
       "11     saw  movie     12   came out.  recall  scarie...\n",
       "12     im   big fan  boll's work     many are.  enjo...\n",
       "13     cast played shakespeare.shakespeare lost.i ap...\n",
       "14      fantastic movie  three prisoners  become fam...\n",
       "15    kind  drawn    erotic scenes,   realize   one ...\n",
       "16     films  simply    remade.   one  them.        ...\n",
       "17     movie made   one   top 10  awful movies. horr...\n",
       "18     remember  film,it   first film   watched   ci...\n",
       "19     awful film!  must      real stinkers   nomina...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5752d6-0fb5-4c73-9a39-52ee1eadafed",
   "metadata": {},
   "source": [
    "## remove_emoji handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f1862b8-a6f6-4135-8f7c-f3ec865ea4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6eefa83e-db27-4770-a6a1-b6d84e55f81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loved the movie. It was '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Loved the movie. It was 😘😘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b260de75-bb96-4ad2-93c7-54571aa6f75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\asit\\anaconda3\\lib\\site-packages (2.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e633d6e-db30-413b-b4d0-f232ddeab47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is :fire:'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "emoji.demojize(\"python is 🔥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26e278-cf7f-4617-9830-b3b765baeb6c",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6313ad6-eafc-4e05-8f40-8134ca560327",
   "metadata": {},
   "source": [
    "## 1. Using the split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47a51163-ceff-41eb-9244-60e1fdbb88e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "sent1 = 'I am going to delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ccd30cd-0022-44ef-8cdc-699467a0c263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ac50059-5990-4934-bb37-db3936609e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = 'I am going to delhi!'\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4c1f0aa-3417-4dc3-9be8-f5bd8cc8fdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where do think I should go? I have 3 day holiday']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 = 'Where do think I should go? I have 3 day holiday'\n",
    "sent4.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3badd4e2-8334-4f0d-b40b-ed18454061c2",
   "metadata": {},
   "source": [
    "## 2. Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "94c757ec-521b-4ffd-8677-9b6e6b6d5208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\Asit\\AppData\\Local\\Temp\\ipykernel_24560\\3190589682.py:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  tokens = re.findall(\"[\\w']+\", sent3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = 'I am going to delhi!'\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "204b6dd0-dfc6-4a0a-9850-5858fdb705c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\\nLorem Ipsum has been the industry's standard dummy text ever since the 1500s,\\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0511914-0939-4416-8e91-e70cc0f4ad58",
   "metadata": {},
   "source": [
    "## 3. NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7138918-3711-4eba-a6e7-811db3803614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de166da6-0e10-4b19-90ff-24095d9f0298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi', '!']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26ea1a0b-b0f6-4d1c-abbd-3165540894ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry?',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s,\\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "502d7289-2295-4b55-81ae-27cd8618f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're here to help! mail us at nks@gmail.com\"\n",
    "sent7 = 'A 5km ride cost $10.50'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a07830a-f254-475b-9224-4fc872318e8a",
   "metadata": {},
   "source": [
    "## 4. Spacy(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "667b1a17-3c1d-4d44-be5d-7a2c1d48976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14b56ae3-a7da-47aa-9a69-c11c35d36e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(sent5)\n",
    "doc2 = nlp(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "763ba05b-af31-477d-aaad-feee189babe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am going to delhi"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4 = nlp(sent1)\n",
    "doc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78a16c7d-ee69-47d2-977a-6b1a266a772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "going\n",
      "to\n",
      "delhi\n"
     ]
    }
   ],
   "source": [
    "for token in doc4:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239c4c5-2e24-4fc4-bd6e-aaaba295ed2f",
   "metadata": {},
   "source": [
    "# Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cdef67d2-b7cd-405b-96b3-c7b566ff4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3a7a4b9-ee35-48b6-a38b-36c28330c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87ce1b7d-52fa-4061-8c9b-280dbd265d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77464523-0e1e-4a10-a693-b35e6d960391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie\n"
     ]
    }
   ],
   "source": [
    "text = 'probably my alltime favorite movie a story of selflessness sacrifice and dedication to a noble cause but its not preachy or boring it just never gets old despite my having seen it some 15 or more times in the last 25 years paul lukas performance brings tears to my eyes and bette davis in one of her very few truly sympathetic roles is a delight the kids are as grandma says more like dressedup midgets than children but that only makes them more fun to watch and the mothers slow awakening to whats happening in the world and under her own roof is believable and startling if i had a dozen thumbs theyd all be up for this movie'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0f7e828e-93ef-474a-9d0b-bead01ef0a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probabl my alltim favorit movi a stori of selfless sacrific and dedic to a nobl caus but it not preachi or bore it just never get old despit my have seen it some 15 or more time in the last 25 year paul luka perform bring tear to my eye and bett davi in one of her veri few truli sympathet role is a delight the kid are as grandma say more like dressedup midget than children but that onli make them more fun to watch and the mother slow awaken to what happen in the world and under her own roof is believ and startl if i had a dozen thumb theyd all be up for thi movi'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a3c31-9a9a-4730-a086-ed104b61b24e",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3183e8aa-5952-4010-89da-8d5e36862ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Asit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He                  He                  \n",
      "was                 be                  \n",
      "running             run                 \n",
      "and                 and                 \n",
      "eating              eat                 \n",
      "at                  at                  \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 have                \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swim                \n",
      "after               after               \n",
      "playing             play                \n",
      "long                long                \n",
      "hours               hours               \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "Sun                 Sun                 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punctuations=\"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word,pos='v')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a91761a4-fb01-422f-a278-5c048afaf3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['probably',\n",
       " 'my',\n",
       " 'alltime',\n",
       " 'favorite',\n",
       " 'movie',\n",
       " 'a',\n",
       " 'story',\n",
       " 'of',\n",
       " 'selflessness',\n",
       " 'sacrifice',\n",
       " 'and',\n",
       " 'dedication',\n",
       " 'to',\n",
       " 'a',\n",
       " 'noble',\n",
       " 'cause',\n",
       " 'but',\n",
       " 'its',\n",
       " 'not',\n",
       " 'preachy',\n",
       " 'or',\n",
       " 'boring',\n",
       " 'it',\n",
       " 'just',\n",
       " 'never',\n",
       " 'gets',\n",
       " 'old',\n",
       " 'despite',\n",
       " 'my',\n",
       " 'having',\n",
       " 'seen',\n",
       " 'it',\n",
       " 'some',\n",
       " '15',\n",
       " 'or',\n",
       " 'more',\n",
       " 'times',\n",
       " 'in',\n",
       " 'the',\n",
       " 'last',\n",
       " '25',\n",
       " 'years',\n",
       " 'paul',\n",
       " 'lukas',\n",
       " 'performance',\n",
       " 'brings',\n",
       " 'tears',\n",
       " 'to',\n",
       " 'my',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'bette',\n",
       " 'davis',\n",
       " 'in',\n",
       " 'one',\n",
       " 'of',\n",
       " 'her',\n",
       " 'very',\n",
       " 'few',\n",
       " 'truly',\n",
       " 'sympathetic',\n",
       " 'roles',\n",
       " 'is',\n",
       " 'a',\n",
       " 'delight',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'are',\n",
       " 'as',\n",
       " 'grandma',\n",
       " 'says',\n",
       " 'more',\n",
       " 'like',\n",
       " 'dressedup',\n",
       " 'midgets',\n",
       " 'than',\n",
       " 'children',\n",
       " 'but',\n",
       " 'that',\n",
       " 'only',\n",
       " 'makes',\n",
       " 'them',\n",
       " 'more',\n",
       " 'fun',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'mothers',\n",
       " 'slow',\n",
       " 'awakening',\n",
       " 'to',\n",
       " 'whats',\n",
       " 'happening',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'and',\n",
       " 'under',\n",
       " 'her',\n",
       " 'own',\n",
       " 'roof',\n",
       " 'is',\n",
       " 'believable',\n",
       " 'and',\n",
       " 'startling',\n",
       " 'if',\n",
       " 'i',\n",
       " 'had',\n",
       " 'a',\n",
       " 'dozen',\n",
       " 'thumbs',\n",
       " 'theyd',\n",
       " 'all',\n",
       " 'be',\n",
       " 'up',\n",
       " 'for',\n",
       " 'this',\n",
       " 'movie']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4cc5bb-c82b-4412-971e-ff4f8798b588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
